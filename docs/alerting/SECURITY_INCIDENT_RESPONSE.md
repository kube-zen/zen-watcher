# Security Incident Response Guide

## Overview
This guide provides actionable runbooks for responding to security alerts generated by Zen Watcher. Each section corresponds to specific alert categories and provides step-by-step incident response procedures.

## üö® Escalation Policies

### Critical-Immediate (0-30 minutes)
- **Response Team**: Security On-Call, SRE Lead
- **Notification**: PagerDuty critical, Slack #security-incidents
- **Documentation**: Full incident report required

### Critical-4h (0-4 hours)
- **Response Team**: Security Team, Engineering Lead
- **Notification**: PagerDuty high, Slack #security
- **Documentation**: Incident summary within 24h

### High-2h (0-2 hours)
- **Response Team**: Security Team
- **Notification**: PagerDuty medium, Slack #security
- **Documentation**: Ticket with resolution plan

### High-24h (Within 24 hours)
- **Response Team**: Security Team, DevOps
- **Notification**: Email, Slack #security
- **Documentation**: Jira ticket with timeline

### Medium-1w (Within 1 week)
- **Response Team**: Engineering team
- **Notification**: Jira ticket
- **Documentation**: Standard issue tracking

---

## üî• Critical Security Events

### Falco Runtime Threats

#### Critical Runtime Threat Detected
**Alert**: `FalcoCriticalRuntimeThreat`
**Response Time**: Immediate (0-30 minutes)

**Immediate Actions**:
1. **Isolate the affected pod**:
   ```bash
   kubectl cordon <node-name>
   kubectl drain <node-name> --ignore-daemonsets --delete-emptydir-data
   ```

2. **Capture forensics**:
   ```bash
   kubectl exec -it <pod-name> -- /bin/sh
   # Capture running processes, network connections, files
   ```

3. **Check container logs**:
   ```bash
   kubectl logs <pod-name> --previous --tail=100
   ```

4. **Review Falco rule details**:
   ```bash
   falco --list-rules | grep <rule-name>
   ```

**Investigation Steps**:
1. Identify the specific Falco rule that triggered
2. Analyze the process tree and file access patterns
3. Check for signs of container escape attempts
4. Review network connections for data exfiltration
5. Examine system call patterns for malicious behavior

**Communication**:
- Notify security team immediately
- Update incident in PagerDuty
- Create secure channel for coordination

**Recovery Steps**:
1. Rebuild affected container from trusted image
2. Update security policies if needed
3. Implement additional monitoring for similar patterns
4. Document lessons learned

---

### Vulnerability Management

#### Critical Vulnerability Detected
**Alert**: `CriticalVulnerabilityDetected`
**Response Time**: 4 hours maximum

**Immediate Actions**:
1. **Identify affected resources**:
   ```bash
   kubectl get pods -A -o json | jq '.items[] | select(.spec.containers[]?.image? | contains("<cve-id>")) | {namespace: .metadata.namespace, name: .metadata.name}'
   ```

2. **Check CVE details**:
   ```bash
   trivy image <image-name> --format json | jq '.Results[]?.Vulnerabilities[]? | select(.VulnerabilityID == "<cve-id>")'
   ```

3. **Assess exploitability**:
   - Check NVD database for exploit code availability
   - Evaluate if vulnerability is remotely exploitable
   - Determine if affected service is internet-facing

**Response Actions**:
1. **Image update** (preferred):
   ```bash
   # Update to patched version
   kubectl set image deployment/<deployment> <container>=<new-image>:<version> -n <namespace>
   ```

2. **Vulnerability scanning**:
   ```bash
   # Rescan after updates
   trivy image <new-image>
   ```

3. **Network isolation** (if patch unavailable):
   ```bash
   # Apply network policies to restrict access
   kubectl apply -f - <<EOF
   apiVersion: networking.k8s.io/v1
   kind: NetworkPolicy
   metadata:
     name: restrict-access
     namespace: <namespace>
   spec:
     podSelector:
       matchLabels:
         app: <affected-app>
     policyTypes:
     - Ingress
     - Egress
     ingress: []
     egress: []
   EOF
   ```

**Documentation Requirements**:
- CVE tracking ticket
- Response timeline
- Risk assessment
- Validation results

---

### Compliance and CIS Benchmarks

#### CIS Benchmark Critical Failure
**Alert**: `CISBenchmarkCriticalFailure`
**Response Time**: 24 hours maximum

**Immediate Actions**:
1. **Run kube-bench manually**:
   ```bash
   kubectl run --rm -i --restart=Never --image=aquasec/kube-bench:latest -- kube-bench node
   ```

2. **Identify specific test failures**:
   ```bash
   kubectl logs -l app=kube-bench | grep -A 10 -B 5 "FAIL"
   ```

3. **Review cluster configuration**:
   ```bash
   # Check API server configuration
   kubectl get configmap kube-apiserver-$(hostname) -n kube-system -o yaml
   ```

**Common Response Steps**:

**Test 1.1.1** (API server configuration):
```bash
# Edit API server manifest
sudo vi /etc/kubernetes/manifests/kube-apiserver.yaml

# Add or ensure these flags are set:
# --authorization-mode=Node,RBAC
# --enable-admission-plugins=NodeRestriction,PodSecurityPolicy
# --audit-log-path=/var/log/kubernetes/audit.log
# --audit-log-maxage=30
# --audit-log-maxbackup=10
# --audit-log-maxsize=100
```

**Test 1.2.1** ( kubelet configuration):
```bash
# Edit kubelet config
sudo vi /var/lib/kubelet/config.yaml

# Ensure:
# authentication:
#   anonymous:
#     enabled: false
# authorization:
#   mode: Webhook
```

**Test 1.3.1** (etcd configuration):
```bash
# Edit etcd configuration
sudo vi /etc/kubernetes/manifests/etcd.yaml

# Ensure:
# --client-cert-auth=true
# --peer-client-cert-auth=true
# --cert-file=/etc/kubernetes/pki/etcd/server.crt
```

**Validation**:
```bash
# Re-run kube-bench
kubectl delete job -l app=kube-bench
kubectl run kube-bench --image=aquasec/kube-bench:latest --restart=Never -- kube-bench node
```

---

### Infrastructure as Code Security

#### Critical IaC Issue
**Alert**: `CriticalIaCIssue`
**Response Time**: 24 hours maximum

**Investigation Steps**:
1. **Identify the violating resource**:
   ```bash
   # Find resources with violations
   kubectl get all -A -o json | jq '.items[] | select(.metadata.labels["checkov.kubernetes.io/check-id"]?) | {kind: .kind, name: .metadata.name, namespace: .metadata.namespace}'
   ```

2. **Review Checkov configuration**:
   ```bash
   # Run Checkov locally
   checkov -f <iac-file> --check <check-id>
   ```

3. **Analyze the specific security issue**:
   ```bash
   # Get detailed checkov output
   checkov -f <iac-file> --check <check-id> --external-checks-dir /path/to/checks
   ```

**Common Critical Issues and Fixes**:

**CKV_K8S_1** (Privileged containers):
```yaml
# BAD
apiVersion: v1
kind: Pod
metadata:
  name: privileged-pod
spec:
  containers:
  - name: container
    securityContext:
      privileged: true

# GOOD
apiVersion: v1
kind: Pod
metadata:
  name: secure-pod
spec:
  containers:
  - name: container
    securityContext:
      runAsNonRoot: true
      runAsUser: 1000
      allowPrivilegeEscalation: false
      capabilities:
        drop:
        - ALL
```

**CKV_K8S_2** (Missing resource limits):
```yaml
# BAD
apiVersion: v1
kind: Pod
metadata:
  name: no-limits-pod
spec:
  containers:
  - name: container
    image: nginx

# GOOD
apiVersion: v1
kind: Pod
metadata:
  name: limited-pod
spec:
  containers:
  - name: container
    image: nginx
    resources:
      requests:
        memory: "64Mi"
        cpu: "250m"
      limits:
        memory: "128Mi"
        cpu: "500m"
```

**CKV_K8S_3** (Missing network policies):
```yaml
# Apply default deny policy
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: default-deny-all
  namespace: production
spec:
  podSelector: {}
  policyTypes:
  - Ingress
  - Egress
```

**Validation**:
```bash
# Re-run Checkov
checkov -d . --check <check-id>
```

---

## üîç High Priority Security Events

### Audit Log Analysis

#### Unauthorized Access Attempt
**Alert**: `UnauthorizedAccessAttempt`
**Response Time**: 2 hours maximum

**Investigation Steps**:
1. **Review audit logs**:
   ```bash
   # Get audit logs for specific user
   kubectl logs -n kube-system -l component=kube-apiserver | grep "<username>"
   ```

2. **Analyze access patterns**:
   ```bash
   # Check for unusual verb patterns
   kubectl logs -n kube-system -l component=kube-apiserver | \
   grep "<username>" | \
   jq '.verb' | sort | uniq -c
   ```

3. **Review RBAC permissions**:
   ```bash
   # Check user/group roles
   kubectl auth can-i --list --as="<username>"
   kubectl get clusterrolebindings | grep "<username>"
   ```

**Common Response Actions**:
1. **Revoke inappropriate permissions**:
   ```bash
   kubectl delete clusterrolebinding <inappropriate-binding>
   ```

2. **Implement least privilege**:
   ```bash
   # Create specific namespace role
   kubectl create rolebinding <user>-edit \
     --clusterrole=edit \
     --user=<username> \
     --namespace=<specific-namespace>
   ```

3. **Enable audit logging**:
   ```yaml
   # kube-apiserver configuration
   --audit-log-path=/var/log/kubernetes/audit.log
   --audit-log-maxage=30
   --audit-log-maxbackup=10
   --audit-log-maxsize=100
   --audit-policy-file=/etc/kubernetes/audit-policy.yaml
   ```

---

## ü§ñ Anomaly Detection

### Security Event Anomalies
**Alert**: `SecurityEventAnomaly`
**Response Time**: 1 hour maximum

**Investigation Framework**:
1. **Identify the anomaly scope**:
   - Which security tools are showing increased activity?
   - What is the baseline vs. current rate?
   - Are multiple namespaces affected?

2. **Correlate with external events**:
   - Check for recent deployments
   - Look for maintenance windows
   - Verify if increased activity is expected

3. **Analyze event patterns**:
   ```bash
   # Get recent security events
   kubectl get observations -A -o json | \
   jq '.items[] | select(.spec.severity? | strings | test("CRITICAL|HIGH")) | {timestamp: .spec.timestamp, source: .spec.source, severity: .spec.severity, message: .spec.message}'
   ```

**Response Actions**:
1. **If legitimate**: Update baselines and thresholds
2. **If suspicious**: Follow incident response procedures
3. **If malicious**: Escalate to critical incident response

---

## üìä Tool-Specific Response Procedures

### Kyverno Policy Violations
**Alert**: `PolicyViolationCritical`
**Response Time**: Immediate

**Investigation**:
```bash
# Check policy status
kubectl get policyreports -A

# Review specific violation
kubectl describe policyreport <report-name>

# Check policy configuration
kubectl get clusterpolicies -o yaml
```

**Response Actions**:
1. **Update policy if too restrictive**:
   ```bash
   kubectl patch clusterpolicy <policy-name> --type='merge' -p='{"spec":{"rules":[{"name":"rule-name","match":{"any":[{"resources":{"kinds":["Pod"]}}]}}]}}'
   ```

2. **Fix resource to comply**:
   ```bash
   # Update resource to meet policy requirements
   kubectl apply -f compliant-resource.yaml
   ```

3. **Create policy exception** (temporary):
   ```yaml
   apiVersion: kyverno.io/v1
   kind: PolicyException
   metadata:
     name: temporary-exception
   spec:
     exceptions:
     - policyName: <policy-name>
       ruleNames:
       - <rule-name>
     match:
       any:
       - resources:
           kinds:
           - Pod
           names:
           - <resource-name>
   ```

---

## üìà Performance and Health

### Tool Performance Issues
**Alert**: `FalcoPerformanceIssues`
**Response Time**: 4 hours maximum

**Performance Investigation**:
1. **Check system resources**:
   ```bash
   # CPU and memory usage
   kubectl top nodes
   kubectl top pods -n falco
   ```

2. **Review Falco metrics**:
   ```bash
   # If Falco exposes metrics
   curl http://falco-metrics:8765/metrics
   ```

3. **Check event processing**:
   ```bash
   # Zen Watcher processing latency
   kubectl logs -n zen-system -l app=zen-watcher | grep "processing_duration"
   ```

**Optimization Steps**:
1. **Scale Falco deployment**:
   ```bash
   kubectl scale deployment falco --replicas=3 -n falco
   ```

2. **Optimize Zen Watcher filters**:
   ```yaml
   # Update Ingester to reduce noise
   spec:
     filter:
       minPriority: 0.7  # Increase threshold
     thresholds:
       observationsPerMinute:
         warning: 50     # Lower threshold
         critical: 100
   ```

3. **Adjust processing order**:
   ```yaml
   spec:
     processingOrder:
       - filter
       - dedup
       - normalization
   ```

---

## üîß False Positive Management

### High False Positive Rate
**Alert**: `HighFalsePositiveRate`
**Response Time**: 1 week

**Analysis Process**:
1. **Identify noisy rules**:
   ```bash
   # Get top rules by volume
   kubectl get observations -A -o json | \
   jq '.items | group_by(.spec.rule_name) | map({rule: .[0].spec.rule_name, count: length}) | sort_by(-.count)'
   ```

2. **Review rule effectiveness**:
   ```bash
   # Check for false positives in recent alerts
   kubectl get observations -A -o json | \
   jq '.items[] | select(.spec.message | contains("suspicious|unauthorized")) | {timestamp: .spec.timestamp, namespace: .spec.namespace, pod: .spec.pod_name}'
   ```

**Rule Tuning Strategies**:
1. **Adjust thresholds**:
   ```yaml
   spec:
     filter:
       minPriority: 0.6  # Increase to reduce noise
     excludePatterns:
       - "*.kube-system.*"
       - "system:*"
   ```

2. **Add namespace exclusions**:
   ```yaml
   spec:
     filter:
       excludeNamespaces:
       - kube-system
       - kube-public
       - kube-node-lease
   ```

3. **Implement time-based filtering**:
   ```yaml
   spec:
     filter:
       timeWindow:
         start: "08:00"
         end: "18:00"
         timezone: "UTC"
   ```

---

## üìã Documentation Templates

### Incident Report Template

```markdown
# Security Incident Report

## Incident Details
- **Incident ID**: INC-YYYY-MM-DD-###
- **Severity**: [Critical|High|Medium|Low]
- **Start Time**: YYYY-MM-DD HH:MM UTC
- **End Time**: YYYY-MM-DD HH:MM UTC
- **Duration**: X hours Y minutes
- **Status**: [Open|In Progress|Resolved|Closed]

## Alert Information
- **Alert Name**: [Alert that triggered]
- **Affected Resources**: [List of resources]
- **Initial Detection**: [How the incident was detected]

## Timeline
| Time | Action | Actor |
|------|--------|-------|
| HH:MM | Detection | Zen Watcher |
| HH:MM | Investigation started | Response team |
| HH:MM | Containment action | Security team |
| HH:MM | Response actions completed | Engineering |

## Root Cause Analysis
[Detailed explanation of what happened and why]

## Impact Assessment
- **Systems Affected**: [List of affected systems]
- **Data Impact**: [Any data exposure or loss]
- **Service Impact**: [Downtime or performance impact]

## Actions Taken
1. [Immediate containment steps]
2. [Investigation steps]
3. [Response actions]
4. [Communication actions]

## Lessons Learned
- [What went well]
- [What could be improved]
- [Process improvements needed]

## Follow-up Actions
- [ ] Action item 1 - Owner: [name] - Due: [date]
- [ ] Action item 2 - Owner: [name] - Due: [date]

## References
- Alert: [link to alert details]
- Investigation notes: [link to investigation docs]
- Communication thread: [link to Slack/email thread]
```

### Weekly Security Summary Template

```markdown
# Weekly Security Summary - Week of YYYY-MM-DD

## Executive Summary
[Brief overview of security posture this week]

## Key Metrics
- **Total Security Events**: [Review dashboard metrics] (‚Üë/‚Üì [calculate]% vs last week)
- **Critical Events**: XX (‚Üë/‚Üì X% vs last week)
- **High Events**: XX (‚Üë/‚Üì X% vs last week)
- **Compliance Score**: XX% (‚Üë/‚Üì X% vs last week)

## Event Breakdown by Source
| Source | Critical | High | Medium | Low | Total |
|--------|----------|------|--------|-----|-------|
| Falco | X | X | X | X | X |
| Trivy | X | X | X | X | X |
| Kube-Bench | X | X | X | X | X |
| Checkov | X | X | X | X | X |
| Audit | X | X | X | X | X |
| Kyverno | X | X | X | X | X |

## Notable Incidents
### Critical Incident 1
- **Description**: [Brief description]
- **Response Time**: [X hours]
- **Resolution**: [How it was resolved]

### High Priority Issues
- [List of high priority issues resolved]

## Compliance Status
- **CIS Benchmark**: XX% compliant (X failures)
- **IaC Security**: XX% compliant (X violations)
- **Vulnerability Management**: XX% of CVEs patched

## Action Items
- [ ] Action item 1 - Owner: [name] - Due: [date]
- [ ] Action item 2 - Owner: [name] - Due: [date]

## Recommendations
1. [Security improvement recommendation 1]
2. [Security improvement recommendation 2]

## Appendix
- Detailed metrics: [link to Grafana dashboard]
- Investigation reports: [link to incident reports]
```

---

## üéØ Quick Reference

### Emergency Contacts
- **Security On-Call**: PagerDuty critical
- **SRE Lead**: PagerDuty high
- **Security Team**: Slack #security-incidents

### Useful Commands
```bash
# Quick security event overview
kubectl get observations -A --sort-by='.# Recent critical eventsspec.timestamp' | tail -20


kubectl get observations -A -o json | \
jq '.items[] | select(.spec.severity? | strings | test("CRITICAL|HIGH")) | {timestamp: .spec.timestamp, source: .spec.source, namespace: .spec.namespace, severity: .spec.severity}'

# Check security tool status
kubectl get pods -A | grep -E "falco|trivy|kube-bench"

# Zen Watcher status
kubectl get pods -n zen-system | grep zen-watcher
```

### Runbook Index
- [Falco Runtime Threats](#falco-runtime-threats)
- [Critical Vulnerabilities](#vulnerability-management)
- [CIS Benchmark Failures](#compliance-and-cis-benchmarks)
- [IaC Security Issues](#infrastructure-as-code-security)
- [Audit Log Anomalies](#audit-log-analysis)
- [Security Event Anomalies](#security-event-anomalies)
- [Policy Violations](#kyverno-policy-violations)
- [Tool Performance Issues](#performance-and-health)
- [False Positive Management](#false-positive-management)

---

*This document is maintained by the Security Team. For updates or questions, contact #security-team on Slack.*