apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: zen-watcher-alerts
  namespace: zen-system
  labels:
    app.kubernetes.io/name: zen-watcher
    app.kubernetes.io/component: monitoring
spec:
  groups:
  - name: zen-watcher-critical
    interval: 30s
    rules:
    - alert: ZenWatcherDown
      expr: up{job="zen-watcher"} == 0
      for: 1m
      labels:
        severity: critical
        component: availability
      annotations:
        summary: "zen-watcher is down"
        description: "zen-watcher pod is not responding. Check pod status: kubectl get pods -n zen-system -l app.kubernetes.io/name=zen-watcher"
        runbook_url: "https://github.com/kube-zen/zen-watcher/docs/TROUBLESHOOTING.md"

    - alert: ZenWatcherHighErrorRate
      expr: |
        (
          sum(rate(zen_watcher_observations_create_errors_total[5m])) +
          sum(rate(zen_watcher_gc_errors_total[5m]))
        ) > 10
      for: 5m
      labels:
        severity: critical
        component: reliability
      annotations:
        summary: "High error rate in zen-watcher"
        description: "{{$value}} errors/sec detected. Check logs: kubectl logs -n zen-system -l app.kubernetes.io/name=zen-watcher --tail=100"

    - alert: ZenWatcherCriticalEventsSpike
      expr: sum(rate(zen_watcher_events_total{severity="critical"}[5m])) * 60 > 20
      for: 2m
      labels:
        severity: critical
        component: security
      annotations:
        summary: "Critical security events spike detected"
        description: "{{$value}} critical events/min detected. Potential security incident."

  - name: zen-watcher-warning
    interval: 30s
    rules:
    - alert: ZenWatcherNoEvents
      expr: sum(rate(zen_watcher_observations_created_total[10m])) == 0
      for: 10m
      labels:
        severity: warning
        component: functionality
      annotations:
        summary: "No observations being created"
        description: "No observations created in last 10 minutes. Check if sources are active and filters aren't too restrictive."

    - alert: ZenWatcherHighFilterRate
      expr: |
        sum(rate(zen_watcher_observations_filtered_total[5m])) /
        (sum(rate(zen_watcher_observations_created_total[5m])) + sum(rate(zen_watcher_observations_filtered_total[5m]))) > 0.9
      for: 10m
      labels:
        severity: warning
        component: configuration
      annotations:
        summary: "High filter rate (>90%)"
        description: "{{$value | humanizePercentage}} of observations are being filtered. Consider reviewing filter configuration."

    - alert: ZenWatcherToolOffline
      expr: sum(zen_watcher_tools_active) by (tool) == 0
      for: 5m
      labels:
        severity: warning
        component: integration
      annotations:
        summary: "Security tool {{$labels.tool}} not detected"
        description: "Tool {{$labels.tool}} has been offline for 5+ minutes. Check if tool is installed and running."

    - alert: ZenWatcherSlowProcessing
      expr: |
        histogram_quantile(0.95, 
          sum(rate(zen_watcher_event_processing_duration_seconds_bucket[5m])) by (le)
        ) > 5
      for: 10m
      labels:
        severity: warning
        component: performance
      annotations:
        summary: "Slow event processing (p95 > 5s)"
        description: "p95 processing latency is {{$value}}s. Check resource constraints and API server load."

    - alert: ZenWatcherWebhookFailing
      expr: |
        sum(rate(zen_watcher_webhook_requests_total{status!="200"}[5m])) /
        sum(rate(zen_watcher_webhook_requests_total[5m])) > 0.1
      for: 5m
      labels:
        severity: warning
        component: integration
      annotations:
        summary: "Webhook endpoint {{$labels.endpoint}} failing"
        description: "{{$value | humanizePercentage}} of requests to {{$labels.endpoint}} are failing (status: {{$labels.status}})"

    - alert: ZenWatcherGCErrors
      expr: rate(zen_watcher_gc_errors_total[5m]) > 0.1
      for: 5m
      labels:
        severity: warning
        component: gc
      annotations:
        summary: "Garbage collection errors detected"
        description: "{{$value}} GC errors/sec. Operation: {{$labels.operation}}, Error: {{$labels.error_type}}"

  - name: zen-watcher-info
    interval: 1m
    rules:
    - alert: ZenWatcherHighDeduplicationRate
      expr: |
        rate(zen_watcher_observations_deduped_total[5m]) /
        (rate(zen_watcher_observations_created_total[5m]) + rate(zen_watcher_observations_deduped_total[5m])) > 0.5
      for: 10m
      labels:
        severity: info
        component: deduplication
      annotations:
        summary: "High deduplication rate (>50%)"
        description: "Many duplicate observations detected. Consider adjusting dedup window or investigating source behavior."

    - alert: ZenWatcherGCFrequent
      expr: rate(zen_watcher_gc_runs_total[1h]) > 2
      for: 1h
      labels:
        severity: info
        component: gc
      annotations:
        summary: "GC running more frequently than expected"
        description: "GC running {{$value}} times/hour. Consider adjusting GC_INTERVAL."

  - name: zen-watcher-performance
    interval: 30s
    rules:
    - alert: ZenWatcherHighThroughput
      expr: sum(rate(zen_watcher_observations_created_total[1m])) * 60 > 100
      for: 5m
      labels:
        severity: info
        component: performance
      annotations:
        summary: "High event throughput detected"
        description: "Processing {{$value}} events/min. Monitor resource usage."

    - alert: ZenWatcherCacheEvictions
      expr: sum(rate(zen_watcher_dedup_evictions_total[5m])) > 1
      for: 5m
      labels:
        severity: warning
        component: cache
      annotations:
        summary: "High cache eviction rate"
        description: "{{$value}} cache evictions/sec. Consider increasing cache size."

    - alert: ZenWatcherWebhookQueueFull
      expr: avg(zen_watcher_webhook_queue_usage_ratio) > 0.8
      for: 2m
      labels:
        severity: warning
        component: webhook
      annotations:
        summary: "Webhook queue near capacity"
        description: "Queue at {{$value | humanizePercentage}} capacity. Risk of dropped events."

    - alert: ZenWatcherAdapterErrors
      expr: rate(zen_watcher_adapter_errors_total[5m]) > 0
      for: 2m
      labels:
        severity: warning
        component: adapter
      annotations:
        summary: "CRD adapter errors detected"
        description: "{{$value}} adapter errors/sec. Mapping: {{$labels.mapping}}, Stage: {{$labels.stage}}"

  - name: zen-watcher-security-insights
    interval: 1m
    rules:
    - alert: ZenWatcherSecuritySpike
      expr: |
        (sum(rate(zen_watcher_events_total{severity=~"critical|high"}[5m])) * 60) >
        (avg_over_time(sum(rate(zen_watcher_events_total{severity=~"critical|high"}[5m]))[1h:5m]) * 60 * 3)
      for: 2m
      labels:
        severity: warning
        component: security
      annotations:
        summary: "Unusual spike in security events"
        description: "Security event rate is 3x higher than 1h average. Possible security incident."

    - alert: ZenWatcherNewToolDetected
      expr: changes(sum(zen_watcher_tools_active) by (tool)[5m]) > 0 and sum(zen_watcher_tools_active) by (tool) > 0
      for: 1m
      labels:
        severity: info
        component: discovery
      annotations:
        summary: "New security tool detected"
        description: "Tool {{$labels.tool}} is now active and being monitored."

    - alert: ZenWatcherMultipleToolsOffline
      expr: count(sum(zen_watcher_tools_active) by (tool) == 0) >= 2
      for: 5m
      labels:
        severity: critical
        component: integration
      annotations:
        summary: "Multiple security tools offline"
        description: "{{$value}} tools are offline. Check cluster health and tool deployments."
